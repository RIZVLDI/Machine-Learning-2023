{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fL0PRK1b6Ho",
        "outputId": "e2dae544-30b8-441e-c7d6-0281b9a5f656"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-2.9816e-11])\n",
            "tensor([ 4.6687e-35,  0.0000e+00, -2.0702e-01])\n",
            "tensor([[4.6697e-35, 0.0000e+00, 4.6697e-35],\n",
            "        [0.0000e+00, 1.9005e-19, 5.0833e+31]])\n",
            "tensor([[[-2.0702e-01,  4.5663e-41,  4.4016e-35],\n",
            "         [ 0.0000e+00,  4.4842e-44,  0.0000e+00]],\n",
            "\n",
            "        [[ 8.9683e-44,  0.0000e+00,  4.4070e-35],\n",
            "         [ 0.0000e+00,  2.0319e-43,  0.0000e+00]]])\n",
            "tensor([[0.7920, 0.2101, 0.3326],\n",
            "        [0.1911, 0.0645, 0.0220],\n",
            "        [0.6585, 0.8347, 0.0984],\n",
            "        [0.6567, 0.7526, 0.8486],\n",
            "        [0.5560, 0.7417, 0.8477]])\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "torch.Size([5, 3])\n",
            "torch.float32\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]], dtype=torch.float16)\n",
            "torch.float16\n",
            "torch.Size([2])\n",
            "tensor([[0.4787, 0.7497, 0.1715],\n",
            "        [0.9980, 0.6213, 0.0536],\n",
            "        [0.3932, 0.3045, 0.3333],\n",
            "        [0.0479, 0.7332, 0.4034],\n",
            "        [0.0267, 0.0703, 0.3581]])\n",
            "tensor([0.4787, 0.9980, 0.3932, 0.0479, 0.0267])\n",
            "tensor([0.9980, 0.6213, 0.0536])\n",
            "tensor(0.6213)\n",
            "0.621333122253418\n",
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n",
            "tensor([1., 1., 1., 1., 1.])\n",
            "[1. 1. 1. 1. 1.]\n",
            "<class 'numpy.ndarray'>\n",
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n",
            "[1. 1. 1. 1. 1.]\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Everything in pytorch is based on Tensor operations.\n",
        "# A tensor can have different dimensions\n",
        "# so it can be 1d, 2d, or even 3d and higher\n",
        "\n",
        "# scalar, vector, matrix, tensor\n",
        "\n",
        "# torch.empty(size): uninitiallized\n",
        "x = torch.empty(1) # scalar\n",
        "print(x)\n",
        "x = torch.empty(3) # vector, 1D\n",
        "print(x)\n",
        "x = torch.empty(2,3) # matrix, 2D\n",
        "print(x)\n",
        "x = torch.empty(2,2,3) # tensor, 3 dimensions\n",
        "#x = torch.empty(2,2,2,3) # tensor, 4 dimensions\n",
        "print(x)\n",
        "\n",
        "# torch.rand(size): random numbers [0, 1]\n",
        "x = torch.rand(5, 3)\n",
        "print(x)\n",
        "\n",
        "# torch.zeros(size), fill with 0\n",
        "# torch.ones(size), fill with 1\n",
        "x = torch.zeros(5, 3)\n",
        "print(x)\n",
        "\n",
        "# check size\n",
        "print(x.size())\n",
        "\n",
        "# check data type\n",
        "print(x.dtype)\n",
        "\n",
        "# specify types, float32 default\n",
        "x = torch.zeros(5, 3, dtype=torch.float16)\n",
        "print(x)\n",
        "\n",
        "# check type\n",
        "print(x.dtype)\n",
        "\n",
        "# construct from data\n",
        "x = torch.tensor([5.5, 3])\n",
        "print(x.size())\n",
        "\n",
        "# requires_grad argument\n",
        "# This will tell pytorch that it will need to calculate the gradients for this tensor\n",
        "# later in your optimization steps\n",
        "# i.e. this is a variable in your model that you want to optimize\n",
        "x = torch.tensor([5.5, 3], requires_grad=True)\n",
        "\n",
        "# Operations\n",
        "y = torch.rand(2, 2)\n",
        "x = torch.rand(2, 2)\n",
        "\n",
        "# elementwise addition\n",
        "z = x + y\n",
        "# torch.add(x,y)\n",
        "\n",
        "# in place addition, everythin with a trailing underscore is an inplace operation\n",
        "# i.e. it will modify the variable\n",
        "# y.add_(x)\n",
        "\n",
        "# substraction\n",
        "z = x - y\n",
        "z = torch.sub(x, y)\n",
        "\n",
        "# multiplication\n",
        "z = x * y\n",
        "z = torch.mul(x,y)\n",
        "\n",
        "# division\n",
        "z = x / y\n",
        "z = torch.div(x,y)\n",
        "\n",
        "# Slicing\n",
        "x = torch.rand(5,3)\n",
        "print(x)\n",
        "print(x[:, 0]) # all rows, column 0\n",
        "print(x[1, :]) # row 1, all columns\n",
        "print(x[1,1]) # element at 1, 1\n",
        "\n",
        "# Get the actual value if only 1 element in your tensor\n",
        "print(x[1,1].item())\n",
        "\n",
        "# Reshape with torch.view()\n",
        "x = torch.randn(4, 4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
        "# if -1 it pytorch will automatically determine the necessary size\n",
        "print(x.size(), y.size(), z.size())\n",
        "\n",
        "# Numpy\n",
        "# Converting a Torch Tensor to a NumPy array and vice versa is very easy\n",
        "a = torch.ones(5)\n",
        "print(a)\n",
        "\n",
        "# torch to numpy with .numpy()\n",
        "b = a.numpy()\n",
        "print(b)\n",
        "print(type(b))\n",
        "\n",
        "# Carful: If the Tensor is on the CPU (not the GPU),\n",
        "# both objects will share the same memory location, so changing one\n",
        "# will also change the other\n",
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "# numpy to torch with .from_numpy(x)\n",
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "# again be careful when modifying\n",
        "a += 1\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "# by default all tensors are created on the CPU,\n",
        "# but you can also move them to the GPU (only if it's available )\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    # z = z.numpy() # not possible because numpy cannot handle GPU tenors\n",
        "    # move to CPU again\n",
        "    z.to(\"cpu\")       # ``.to`` can also change dtype together!\n",
        "    # z = z.numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYiBs-Q3cLpp",
        "outputId": "512ab004-85a6-447a-e2a7-f115105d1cd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-0.2572, -0.6876, -0.0402], requires_grad=True)\n",
            "tensor([1.7428, 1.3124, 1.9598], grad_fn=<AddBackward0>)\n",
            "<AddBackward0 object at 0x7f4aacc9d360>\n",
            "tensor([ 9.1115,  5.1670, 11.5225], grad_fn=<MulBackward0>)\n",
            "tensor(8.6003, grad_fn=<MeanBackward0>)\n",
            "tensor([3.4855, 2.6248, 3.9196])\n",
            "tensor([ -211.8870, -2834.6411, -2974.8743], grad_fn=<MulBackward0>)\n",
            "torch.Size([3])\n",
            "tensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n",
            "False\n",
            "None\n",
            "True\n",
            "<SumBackward0 object at 0x7f4aacc9d270>\n",
            "True\n",
            "False\n",
            "True\n",
            "False\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([0.1000, 0.1000, 0.1000, 0.1000], requires_grad=True)\n",
            "tensor(4.8000, grad_fn=<SumBackward0>)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "# The autograd package provides automatic differentiation\n",
        "# for all operations on Tensors\n",
        "\n",
        "# requires_grad = True -> tracks all operations on the tensor.\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "y = x + 2\n",
        "\n",
        "# y was created as a result of an operation, so it has a grad_fn attribute.\n",
        "# grad_fn: references a Function that has created the Tensor\n",
        "print(x) # created by the user -> grad_fn is None\n",
        "print(y)\n",
        "print(y.grad_fn)\n",
        "\n",
        "# Do more operations on y\n",
        "z = y * y * 3\n",
        "print(z)\n",
        "z = z.mean()\n",
        "print(z)\n",
        "\n",
        "# Let's compute the gradients with backpropagation\n",
        "# When we finish our computation we can call .backward() and have all the gradients computed automatically.\n",
        "# The gradient for this tensor will be accumulated into .grad attribute.\n",
        "# It is the partial derivate of the function w.r.t. the tensor\n",
        "\n",
        "z.backward()\n",
        "print(x.grad) # dz/dx\n",
        "\n",
        "# Generally speaking, torch.autograd is an engine for computing vector-Jacobian product\n",
        "# It computes partial derivates while applying the chain rule\n",
        "\n",
        "# -------------\n",
        "# Model with non-scalar output:\n",
        "# If a Tensor is non-scalar (more than 1 elements), we need to specify arguments for backward()\n",
        "# specify a gradient argument that is a tensor of matching shape.\n",
        "# needed for vector-Jacobian product\n",
        "\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "for _ in range(10):\n",
        "    y = y * 2\n",
        "\n",
        "print(y)\n",
        "print(y.shape)\n",
        "\n",
        "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float32)\n",
        "y.backward(v)\n",
        "print(x.grad)\n",
        "\n",
        "# -------------\n",
        "# Stop a tensor from tracking history:\n",
        "# For example during our training loop when we want to update our weights\n",
        "# then this update operation should not be part of the gradient computation\n",
        "# - x.requires_grad_(False)\n",
        "# - x.detach()\n",
        "# - wrap in 'with torch.no_grad():'\n",
        "\n",
        "# .requires_grad_(...) changes an existing flag in-place.\n",
        "a = torch.randn(2, 2)\n",
        "print(a.requires_grad)\n",
        "b = ((a * 3) / (a - 1))\n",
        "print(b.grad_fn)\n",
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)\n",
        "b = (a * a).sum()\n",
        "print(b.grad_fn)\n",
        "\n",
        "# .detach(): get a new Tensor with the same content but no gradient computation:\n",
        "a = torch.randn(2, 2, requires_grad=True)\n",
        "print(a.requires_grad)\n",
        "b = a.detach()\n",
        "print(b.requires_grad)\n",
        "\n",
        "# wrap in 'with torch.no_grad():'\n",
        "a = torch.randn(2, 2, requires_grad=True)\n",
        "print(a.requires_grad)\n",
        "with torch.no_grad():\n",
        "    print((x ** 2).requires_grad)\n",
        "\n",
        "# -------------\n",
        "# backward() accumulates the gradient for this tensor into .grad attribute.\n",
        "# !!! We need to be careful during optimization !!!\n",
        "# Use .zero_() to empty the gradients before a new optimization step!\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "    # just a dummy example\n",
        "    model_output = (weights*3).sum()\n",
        "    model_output.backward()\n",
        "\n",
        "    print(weights.grad)\n",
        "\n",
        "    # optimize model, i.e. adjust weights...\n",
        "    with torch.no_grad():\n",
        "        weights -= 0.1 * weights.grad\n",
        "\n",
        "    # this is important! It affects the final weights & output\n",
        "    weights.grad.zero_()\n",
        "\n",
        "print(weights)\n",
        "print(model_output)\n",
        "\n",
        "# Optimizer has zero_grad() method\n",
        "# optimizer = torch.optim.SGD([weights], lr=0.1)\n",
        "# During training:\n",
        "# optimizer.step()\n",
        "# optimizer.zero_grad()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7az9lZecgDg",
        "outputId": "27548005-8fa7-4aa5-8a43-129e935943c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n",
            "tensor(-4.)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "x = torch.tensor(2.0)\n",
        "y = torch.tensor(3.0)\n",
        "\n",
        "# This is the parameter we want to optimize -> requires_grad=True\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# forward pass to compute loss\n",
        "y_predicted = w * x\n",
        "loss = (y_predicted - y)**2\n",
        "print(loss)\n",
        "\n",
        "# backward pass to compute gradient dLoss/dw\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "\n",
        "# update weights\n",
        "# next forward and backward pass...\n",
        "\n",
        "# continue optimizing:\n",
        "# update weights, this operation should not be part of the computational graph\n",
        "with torch.no_grad():\n",
        "    w -= 0.01 * w.grad\n",
        "# don't forget to zero the gradients\n",
        "w.grad.zero_()\n",
        "\n",
        "# next forward and backward pass...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RdyM09dcr1w",
        "outputId": "bc5092cc-e7b5-4d10-a91e-f427002a9fed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction before training: f(5) = 0.000\n",
            "epoch 1: w = 0.540, loss = 54.00000000\n",
            "epoch 11: w = 1.937, loss = 0.09973580\n",
            "epoch 21: w = 1.997, loss = 0.00018420\n",
            "epoch 31: w = 2.000, loss = 0.00000034\n",
            "epoch 41: w = 2.000, loss = 0.00000000\n",
            "epoch 51: w = 2.000, loss = 0.00000000\n",
            "epoch 61: w = 2.000, loss = 0.00000000\n",
            "epoch 71: w = 2.000, loss = 0.00000000\n",
            "epoch 81: w = 2.000, loss = 0.00000000\n",
            "epoch 91: w = 2.000, loss = 0.00000000\n",
            "Prediction after training: f(5) = 10.000\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Here we replace the manually computed gradient with autograd\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x\n",
        "\n",
        "# here : f = 2 * x\n",
        "X = torch.tensor([2, 3, 4, 5], dtype=torch.float32)\n",
        "Y = torch.tensor([4, 6, 8, 10], dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# model output\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "# loss = MSE\n",
        "def loss(y, y_pred):\n",
        "    return ((y_pred - y)**2).mean()\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5).item():.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass\n",
        "    y_pred = forward(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_pred)\n",
        "\n",
        "    # calculate gradients = backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    #w.data = w.data - learning_rate * w.grad\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "\n",
        "    # zero the gradients after updating\n",
        "    w.grad.zero_()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'epoch {epoch+1}: w = {w.item():.3f}, loss = {l.item():.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5).item():.3f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpLb1UC0c9qQ",
        "outputId": "5eecea75-b477-47e0-e47a-927bb9f6e198"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#samples: 4, #features: 1\n",
            "Prediction before training: f(5) = 2.466\n",
            "epoch  1 : w =  0.7124106884002686  loss =  tensor(28.6611, grad_fn=<MseLossBackward0>)\n",
            "epoch  11 : w =  1.654364824295044  loss =  tensor(0.1658, grad_fn=<MseLossBackward0>)\n",
            "epoch  21 : w =  1.690994381904602  loss =  tensor(0.1295, grad_fn=<MseLossBackward0>)\n",
            "epoch  31 : w =  1.697335958480835  loss =  tensor(0.1250, grad_fn=<MseLossBackward0>)\n",
            "epoch  41 : w =  1.7025789022445679  loss =  tensor(0.1208, grad_fn=<MseLossBackward0>)\n",
            "epoch  51 : w =  1.7076988220214844  loss =  tensor(0.1166, grad_fn=<MseLossBackward0>)\n",
            "epoch  61 : w =  1.7127294540405273  loss =  tensor(0.1127, grad_fn=<MseLossBackward0>)\n",
            "epoch  71 : w =  1.717673420906067  loss =  tensor(0.1088, grad_fn=<MseLossBackward0>)\n",
            "epoch  81 : w =  1.7225323915481567  loss =  tensor(0.1051, grad_fn=<MseLossBackward0>)\n",
            "epoch  91 : w =  1.7273077964782715  loss =  tensor(0.1015, grad_fn=<MseLossBackward0>)\n",
            "Prediction after training: f(5) = 9.687\n"
          ]
        }
      ],
      "source": [
        "# 1) Design model (input, output, forward pass with different layers)\n",
        "# 2) Construct loss and optimizer\n",
        "# 3) Training loop\n",
        "#       - Forward = compute prediction and loss\n",
        "#       - Backward = compute gradients\n",
        "#       - Update weights\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x\n",
        "\n",
        "# here : f = 2 * x\n",
        "\n",
        "# 0) Training samples, watch the shape!\n",
        "X = torch.tensor([[2], [3], [4], [5]], dtype=torch.float32)\n",
        "Y = torch.tensor([[4], [6], [8], [10]], dtype=torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(f'#samples: {n_samples}, #features: {n_features}')\n",
        "# 0) create a test sample\n",
        "X_test = torch.tensor([5], dtype=torch.float32)\n",
        "\n",
        "# 1) Design Model, the model has to implement the forward pass!\n",
        "# Here we can use a built-in model from PyTorch\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "# we can call this model with samples X\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "'''\n",
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LinearRegression, self).__init__()\n",
        "        # define diferent layers\n",
        "        self.lin = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lin(x)\n",
        "\n",
        "model = LinearRegression(input_size, output_size)\n",
        "'''\n",
        "\n",
        "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n",
        "\n",
        "# 2) Define loss and optimizer\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass with our model\n",
        "    y_predicted = model(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_predicted)\n",
        "\n",
        "    # calculate gradients = backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero the gradients after updating\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        [w, b] = model.parameters() # unpack parameters\n",
        "        print('epoch ', epoch+1, ': w = ', w[0][0].item(), ' loss = ', l)\n",
        "\n",
        "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "id": "YEBE1gP0dM9h",
        "outputId": "05944c72-8b83-4073-d741-a96e6a9e9108"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 10, loss = 2314.4832\n",
            "epoch: 20, loss = 1827.6394\n",
            "epoch: 30, loss = 1496.9691\n",
            "epoch: 40, loss = 1272.3623\n",
            "epoch: 50, loss = 1119.7914\n",
            "epoch: 60, loss = 1016.1476\n",
            "epoch: 70, loss = 945.7377\n",
            "epoch: 80, loss = 897.9026\n",
            "epoch: 90, loss = 865.4030\n",
            "epoch: 100, loss = 843.3215\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 0) Prepare data\n",
        "X_numpy, y_numpy = datasets.make_regression(n_samples=150, n_features=1, noise=30, random_state=6)\n",
        "\n",
        "# cast to float Tensor\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
        "y = y.view(y.shape[0], 1)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "# 1) Model\n",
        "# Linear model f = wx + b\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "# 2) Loss and optimizer\n",
        "learning_rate = 0.01\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass and loss\n",
        "    y_predicted = model(X)\n",
        "    loss = criterion(y_predicted, y)\n",
        "\n",
        "    # Backward pass and update\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero grad before new step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "# Plot\n",
        "predicted = model(X).detach().numpy()\n",
        "\n",
        "plt.plot(X_numpy, y_numpy, 'ro')\n",
        "plt.plot(X_numpy, predicted, 'b')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkrqwbg2dZD5",
        "outputId": "70600798-9147-44d8-9763-66716006711e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 20, loss = 0.4937\n",
            "epoch: 40, loss = 0.3792\n",
            "epoch: 60, loss = 0.3170\n",
            "epoch: 80, loss = 0.2775\n",
            "epoch: 100, loss = 0.2497\n",
            "accuracy: 0.8947\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 0) Prepare data\n",
        "bc = datasets.load_breast_cancer()\n",
        "X, y = bc.data, bc.target\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "\n",
        "# scale\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "y_train = y_train.view(y_train.shape[0], 1)\n",
        "y_test = y_test.view(y_test.shape[0], 1)\n",
        "\n",
        "# 1) Model\n",
        "# Linear model f = wx + b , sigmoid at the end\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear = nn.Linear(n_input_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred\n",
        "\n",
        "model = Model(n_features)\n",
        "\n",
        "# 2) Loss and optimizer\n",
        "num_epochs = 100\n",
        "learning_rate = 0.01\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass and loss\n",
        "    y_pred = model(X_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "\n",
        "    # Backward pass and update\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero grad before new step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 20 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_predicted = model(X_test)\n",
        "    y_predicted_cls = y_predicted.round()\n",
        "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
        "    print(f'accuracy: {acc.item():.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDuxtbG6djG5",
        "outputId": "e4d7e11e-872f-4aaa-cdd3-b8fdb6022d0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([3.7370e+01, 2.7000e+01, 3.8850e+03, 6.6100e+02, 1.5370e+03, 6.0600e+02,\n",
            "        6.6085e+00, 3.4470e+05]) tensor([-122.0500])\n",
            "tensor([[3.6570e+01, 1.3000e+01, 2.6850e+03, 6.2100e+02, 2.4740e+03, 5.7300e+02,\n",
            "         2.8775e+00, 1.3410e+05],\n",
            "        [3.7960e+01, 3.7000e+01, 1.2170e+03, 1.9900e+02, 5.5200e+02, 1.9400e+02,\n",
            "         5.0445e+00, 1.9620e+05],\n",
            "        [3.2760e+01, 4.1000e+01, 1.5450e+03, 4.2000e+02, 7.4700e+02, 4.1500e+02,\n",
            "         2.3750e+00, 1.5440e+05],\n",
            "        [3.7880e+01, 5.2000e+01, 2.6040e+03, 8.3700e+02, 1.7980e+03, 7.6900e+02,\n",
            "         1.7250e+00, 2.8750e+05]]) tensor([[-121.4200],\n",
            "        [-122.0700],\n",
            "        [-117.1300],\n",
            "        [-122.2600]])\n",
            "3000 750\n",
            "Epoch: 1/2, Step 5/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 10/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 15/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 20/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 25/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 30/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 35/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 40/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 45/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 50/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 55/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 60/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 65/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 70/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 75/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 80/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 85/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 90/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 95/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 100/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 105/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 110/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 115/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 120/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 125/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 130/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 135/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 140/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 145/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 150/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 155/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 160/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 165/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 170/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 175/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 180/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 185/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 190/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 195/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 200/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 205/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 210/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 215/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 220/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 225/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 230/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 235/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 240/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 245/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 250/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 255/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 260/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 265/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 270/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 275/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 280/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 285/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 290/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 295/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 300/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 305/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 310/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 315/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 320/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 325/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 330/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 335/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 340/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 345/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 350/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 355/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 360/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 365/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 370/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 375/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 380/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 385/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 390/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 395/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 400/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 405/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 410/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 415/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 420/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 425/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 430/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 435/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 440/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 445/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 450/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 455/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 460/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 465/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 470/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 475/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 480/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 485/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 490/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 495/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 500/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 505/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 510/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 515/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 520/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 525/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 530/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 535/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 540/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 545/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 550/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 555/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 560/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 565/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 570/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 575/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 580/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 585/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 590/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 595/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 600/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 605/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 610/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 615/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 620/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 625/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 630/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 635/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 640/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 645/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 650/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 655/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 660/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 665/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 670/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 675/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 680/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 685/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 690/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 695/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 700/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 705/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 710/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 715/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 720/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 725/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 730/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 735/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 740/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 745/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 750/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 5/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 10/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 15/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 20/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 25/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 30/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 35/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 40/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 45/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 50/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 55/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 60/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 65/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 70/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 75/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 80/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 85/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 90/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 95/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 100/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 105/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 110/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 115/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 120/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 125/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 130/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 135/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 140/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 145/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 150/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 155/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 160/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 165/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 170/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 175/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 180/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 185/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 190/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 195/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 200/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 205/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 210/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 215/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 220/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 225/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 230/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 235/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 240/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 245/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 250/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 255/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 260/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 265/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 270/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 275/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 280/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 285/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 290/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 295/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 300/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 305/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 310/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 315/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 320/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 325/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 330/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 335/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 340/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 345/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 350/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 355/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 360/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 365/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 370/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 375/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 380/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 385/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 390/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 395/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 400/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 405/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 410/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 415/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 420/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 425/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 430/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 435/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 440/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 445/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 450/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 455/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 460/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 465/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 470/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 475/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 480/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 485/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 490/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 495/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 500/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 505/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 510/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 515/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 520/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 525/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 530/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 535/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 540/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 545/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 550/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 555/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 560/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 565/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 570/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 575/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 580/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 585/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 590/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 595/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 600/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 605/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 610/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 615/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 620/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 625/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 630/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 635/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 640/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 645/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 650/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 655/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 660/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 665/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 670/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 675/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 680/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 685/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 690/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 695/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 700/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 705/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 710/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 715/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 720/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 725/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 730/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 735/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 740/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 745/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 750/750| Inputs torch.Size([4, 8]) | Labels torch.Size([4, 1])\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 377902608.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 21184976.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 131350972.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 15500837.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 1, 28, 28]) torch.Size([3])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# gradient computation etc. not efficient for whole data set\n",
        "# -> divide dataset into small batches\n",
        "\n",
        "'''\n",
        "# training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # loop over all batches\n",
        "    for i in range(total_batches):\n",
        "        batch_x, batch_y = ...\n",
        "'''\n",
        "\n",
        "# epoch = one forward and backward pass of ALL training samples\n",
        "# batch_size = number of training samples used in one forward/backward pass\n",
        "# number of iterations = number of passes, each pass (forward+backward) using [batch_size] number of sampes\n",
        "# e.g : 100 samples, batch_size=20 -> 100/20=5 iterations for 1 epoch\n",
        "\n",
        "# --> DataLoader can do the batch computation for us\n",
        "\n",
        "# Implement a custom Dataset:\n",
        "# inherit Dataset\n",
        "# implement __init__ , __getitem__ , and __len__\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "        # Initialize data, download, etc.\n",
        "        # read with numpy or pandas\n",
        "        xy = np.loadtxt('/content/sample_data/california_housing_test.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
        "        self.n_samples = xy.shape[0]\n",
        "\n",
        "        # here the first column is the class label, the rest are the features\n",
        "        self.x_data = torch.from_numpy(xy[:, 1:]) # size [n_samples, n_features]\n",
        "        self.y_data = torch.from_numpy(xy[:, [0]]) # size [n_samples, 1]\n",
        "\n",
        "    # support indexing such that dataset[i] can be used to get i-th sample\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    # we can call len(dataset) to return the size\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "\n",
        "# create dataset\n",
        "dataset = WineDataset()\n",
        "\n",
        "# get first sample and unpack\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(features, labels)\n",
        "\n",
        "# Load whole dataset with DataLoader\n",
        "# shuffle: shuffle data, good for training\n",
        "# num_workers: faster loading with multiple subprocesses\n",
        "# !!! IF YOU GET AN ERROR DURING LOADING, SET num_workers TO 0 !!!\n",
        "train_loader = DataLoader(dataset=dataset,\n",
        "                          batch_size=4,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)\n",
        "\n",
        "# convert to an iterator and look at one random sample\n",
        "dataiter = iter(train_loader)\n",
        "data = next(dataiter)\n",
        "features, labels = data\n",
        "print(features, labels)\n",
        "\n",
        "# Dummy Training loop\n",
        "num_epochs = 2\n",
        "total_samples = len(dataset)\n",
        "n_iterations = math.ceil(total_samples/4)\n",
        "print(total_samples, n_iterations)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "\n",
        "        # here: 178 samples, batch_size = 4, n_iters=178/4=44.5 -> 45 iterations\n",
        "        # Run your training process\n",
        "        if (i+1) % 5 == 0:\n",
        "            print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}| Inputs {inputs.shape} | Labels {labels.shape}')\n",
        "\n",
        "# some famous datasets are available in torchvision.datasets\n",
        "# e.g. MNIST, Fashion-MNIST, CIFAR10, COCO\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=torchvision.transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=3,\n",
        "                                           shuffle=True)\n",
        "\n",
        "# look at one random sample\n",
        "dataiter = iter(train_loader)\n",
        "data = next(dataiter)\n",
        "inputs, targets = data\n",
        "print(inputs.shape, targets.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ortkmKsueO2I",
        "outputId": "7b14ceb8-bcd8-4f74-9f02-a794df8eae71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Without Transform\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "[3.7370e+01 2.7000e+01 3.8850e+03 6.6100e+02 1.5370e+03 6.0600e+02\n",
            " 6.6085e+00 3.4470e+05] [-122.05]\n",
            "\n",
            "With Tensor Transform\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "tensor([3.7370e+01, 2.7000e+01, 3.8850e+03, 6.6100e+02, 1.5370e+03, 6.0600e+02,\n",
            "        6.6085e+00, 3.4470e+05]) tensor([-122.0500])\n",
            "\n",
            "With Tensor and Multiplication Transform\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "tensor([1.4948e+02, 1.0800e+02, 1.5540e+04, 2.6440e+03, 6.1480e+03, 2.4240e+03,\n",
            "        2.6434e+01, 1.3788e+06]) tensor([-122.0500])\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Transforms can be applied to PIL images, tensors, ndarrays, or custom data\n",
        "during creation of the DataSet\n",
        "\n",
        "complete list of built-in transforms:\n",
        "https://pytorch.org/docs/stable/torchvision/transforms.html\n",
        "\n",
        "On Images\n",
        "---------\n",
        "CenterCrop, Grayscale, Pad, RandomAffine\n",
        "RandomCrop, RandomHorizontalFlip, RandomRotation\n",
        "Resize, Scale\n",
        "\n",
        "On Tensors\n",
        "----------\n",
        "LinearTransformation, Normalize, RandomErasing\n",
        "\n",
        "Conversion\n",
        "----------\n",
        "ToPILImage: from tensor or ndrarray\n",
        "ToTensor : from numpy.ndarray or PILImage\n",
        "\n",
        "Generic\n",
        "-------\n",
        "Use Lambda\n",
        "\n",
        "Custom\n",
        "------\n",
        "Write own class\n",
        "\n",
        "Compose multiple Transforms\n",
        "---------------------------\n",
        "composed = transforms.Compose([Rescale(256),\n",
        "                               RandomCrop(224)])\n",
        "'''\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "\n",
        "    def __init__(self, transform=None):\n",
        "        xy = np.loadtxt('/content/sample_data/california_housing_test.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
        "        self.n_samples = xy.shape[0]\n",
        "\n",
        "        # note that we do not convert to tensor here\n",
        "        self.x_data = xy[:, 1:]\n",
        "        self.y_data = xy[:, [0]]\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.x_data[index], self.y_data[index]\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "# Custom Transforms\n",
        "# implement __call__(self, sample)\n",
        "class ToTensor:\n",
        "    # Convert ndarrays to Tensors\n",
        "    def __call__(self, sample):\n",
        "        inputs, targets = sample\n",
        "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
        "\n",
        "class MulTransform:\n",
        "    # multiply inputs with a given factor\n",
        "    def __init__(self, factor):\n",
        "        self.factor = factor\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        inputs, targets = sample\n",
        "        inputs *= self.factor\n",
        "        return inputs, targets\n",
        "\n",
        "print('Without Transform')\n",
        "dataset = WineDataset()\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features, labels)\n",
        "\n",
        "print('\\nWith Tensor Transform')\n",
        "dataset = WineDataset(transform=ToTensor())\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features, labels)\n",
        "\n",
        "print('\\nWith Tensor and Multiplication Transform')\n",
        "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(4)])\n",
        "dataset = WineDataset(transform=composed)\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features, labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBy968_reb0q",
        "outputId": "68ce56ca-45ee-408d-ee15-3b70c94e924f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "softmax numpy: [0.70278876 0.25854154 0.0386697 ]\n",
            "softmax torch: tensor([0.7028, 0.2585, 0.0387])\n",
            "Loss1 numpy: 0.2231\n",
            "Loss2 numpy: 2.3026\n",
            "PyTorch Loss1: 1.3295\n",
            "PyTorch Loss2: 4.4195\n",
            "Actual class: 0, Y_pred1: 1, Y_pred2: 1\n",
            "Batch Loss1:  0.2834\n",
            "Batch Loss2: 1.6418\n",
            "Actual class: tensor([2, 0, 1]), Y_pred1: tensor([2, 0, 1]), Y_pred2: tensor([0, 2, 0])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "#\n",
        "#        -> 2.0              -> 0.65\n",
        "# Linear -> 1.0  -> Softmax  -> 0.25   -> CrossEntropy(y, y_hat)\n",
        "#        -> 0.1              -> 0.1\n",
        "#\n",
        "#     scores(logits)      probabilities\n",
        "#                           sum = 1.0\n",
        "#\n",
        "\n",
        "# Softmax applies the exponential function to each element, and normalizes\n",
        "# by dividing by the sum of all these exponentials\n",
        "# -> squashes the output to be between 0 and 1 = probability\n",
        "# sum of all probabilities is 1\n",
        "def softmax(x):\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "\n",
        "x = np.array([3.0, 2.0, 0.1])\n",
        "outputs = softmax(x)\n",
        "print('softmax numpy:', outputs)\n",
        "\n",
        "x = torch.tensor([3.0, 2.0, 0.1])\n",
        "outputs = torch.softmax(x, dim=0) # along values along first axis\n",
        "print('softmax torch:', outputs)\n",
        "\n",
        "# Cross entropy\n",
        "# Cross-entropy loss, or log loss, measures the performance of a classification model\n",
        "# whose output is a probability value between 0 and 1.\n",
        "# -> loss increases as the predicted probability diverges from the actual label\n",
        "def cross_entropy(actual, predicted):\n",
        "    EPS = 1e-15\n",
        "    predicted = np.clip(predicted, EPS, 1 - EPS)\n",
        "    loss = -np.sum(actual * np.log(predicted))\n",
        "    return loss # / float(predicted.shape[0])\n",
        "\n",
        "# y must be one hot encoded\n",
        "# if class 0: [1 0 0]\n",
        "# if class 1: [0 1 0]\n",
        "# if class 2: [0 0 1]\n",
        "Y = np.array([1, 0, 0])\n",
        "Y_pred_good = np.array([0.8, 0.3, 0.2])\n",
        "Y_pred_bad = np.array([0.1, 0.4, 0.6])\n",
        "l1 = cross_entropy(Y, Y_pred_good)\n",
        "l2 = cross_entropy(Y, Y_pred_bad)\n",
        "print(f'Loss1 numpy: {l1:.4f}')\n",
        "print(f'Loss2 numpy: {l2:.4f}')\n",
        "\n",
        "# CrossEntropyLoss in PyTorch (applies Softmax)\n",
        "# nn.LogSoftmax + nn.NLLLoss\n",
        "# NLLLoss = negative log likelihood loss\n",
        "loss = nn.CrossEntropyLoss()\n",
        "# loss(input, target)\n",
        "\n",
        "# target is of size nSamples = 1\n",
        "# each element has class label: 0, 1, or 2\n",
        "# Y (=target) contains class labels, not one-hot\n",
        "Y = torch.tensor([0])\n",
        "\n",
        "# input is of size nSamples x nClasses = 1 x 3\n",
        "# y_pred (=input) must be raw, unnormalizes scores (logits) for each class, not softmax\n",
        "Y_pred_good = torch.tensor([[3.0, 4.0, 0.2]])\n",
        "Y_pred_bad = torch.tensor([[0.6, 5.0, 0.1]])\n",
        "l1 = loss(Y_pred_good, Y)\n",
        "l2 = loss(Y_pred_bad, Y)\n",
        "\n",
        "print(f'PyTorch Loss1: {l1.item():.4f}')\n",
        "print(f'PyTorch Loss2: {l2.item():.4f}')\n",
        "\n",
        "# get predictions\n",
        "_, predictions1 = torch.max(Y_pred_good, 1)\n",
        "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
        "print(f'Actual class: {Y.item()}, Y_pred1: {predictions1.item()}, Y_pred2: {predictions2.item()}')\n",
        "\n",
        "# allows batch loss for multiple samples\n",
        "\n",
        "# target is of size nBatch = 3\n",
        "# each element has class label: 0, 1, or 2\n",
        "Y = torch.tensor([2, 0, 1])\n",
        "\n",
        "# input is of size nBatch x nClasses = 3 x 3\n",
        "# Y_pred are logits (not softmax)\n",
        "Y_pred_good = torch.tensor(\n",
        "    [[0.1, 0.2, 3.9], # predict class 2\n",
        "    [1.2, 0.1, 0.3], # predict class 0\n",
        "    [0.3, 2.2, 0.2]]) # predict class 1\n",
        "\n",
        "Y_pred_bad = torch.tensor(\n",
        "    [[0.9, 0.2, 0.1],\n",
        "    [0.1, 0.3, 1.5],\n",
        "    [1.2, 0.2, 0.5]])\n",
        "\n",
        "l1 = loss(Y_pred_good, Y)\n",
        "l2 = loss(Y_pred_bad, Y)\n",
        "print(f'Batch Loss1:  {l1.item():.4f}')\n",
        "print(f'Batch Loss2: {l2.item():.4f}')\n",
        "\n",
        "# get predictions\n",
        "_, predictions1 = torch.max(Y_pred_good, 1)\n",
        "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
        "print(f'Actual class: {Y}, Y_pred1: {predictions1}, Y_pred2: {predictions2}')\n",
        "\n",
        "# Binary classification\n",
        "class NeuralNet1(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet1, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        # sigmoid at the end\n",
        "        y_pred = torch.sigmoid(out)\n",
        "        return y_pred\n",
        "\n",
        "model = NeuralNet1(input_size=28*28, hidden_size=5)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Multiclass problem\n",
        "class NeuralNet2(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet2, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        # no softmax at the end\n",
        "        return out\n",
        "\n",
        "model = NeuralNet2(input_size=28*28, hidden_size=5, num_classes=3)\n",
        "criterion = nn.CrossEntropyLoss()  # (applies Softmax)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0VBvMY3e-J_",
        "outputId": "91361883-e4c7-406a-ec4b-b575ad913054"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([7.6885e-04, 8.4315e-01, 1.1411e-01, 4.1978e-02])\n",
            "tensor([7.6885e-04, 8.4315e-01, 1.1411e-01, 4.1978e-02])\n",
            "tensor([0.1192, 0.9933, 0.9526, 0.8808])\n",
            "tensor([0.1192, 0.9933, 0.9526, 0.8808])\n",
            "tensor([-0.9640,  0.9999,  0.9951,  0.9640])\n",
            "tensor([-0.9640,  0.9999,  0.9951,  0.9640])\n",
            "tensor([0., 5., 3., 2.])\n",
            "tensor([0., 5., 3., 2.])\n",
            "tensor([-0.0200,  5.0000,  3.0000,  2.0000])\n",
            "tensor([-0.0200,  5.0000,  3.0000,  2.0000])\n"
          ]
        }
      ],
      "source": [
        "# output = w*x + b\n",
        "# output = activation_function(output)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "x = torch.tensor([-2.0, 5.0, 3.0, 2.0])\n",
        "\n",
        "# sofmax\n",
        "output = torch.softmax(x, dim=0)\n",
        "print(output)\n",
        "sm = nn.Softmax(dim=0)\n",
        "output = sm(x)\n",
        "print(output)\n",
        "\n",
        "# sigmoid\n",
        "output = torch.sigmoid(x)\n",
        "print(output)\n",
        "s = nn.Sigmoid()\n",
        "output = s(x)\n",
        "print(output)\n",
        "\n",
        "#tanh\n",
        "output = torch.tanh(x)\n",
        "print(output)\n",
        "t = nn.Tanh()\n",
        "output = t(x)\n",
        "print(output)\n",
        "\n",
        "# relu\n",
        "output = torch.relu(x)\n",
        "print(output)\n",
        "relu = nn.ReLU()\n",
        "output = relu(x)\n",
        "print(output)\n",
        "\n",
        "# leaky relu\n",
        "output = F.leaky_relu(x)\n",
        "print(output)\n",
        "lrelu = nn.LeakyReLU()\n",
        "output = lrelu(x)\n",
        "print(output)\n",
        "\n",
        "#nn.ReLU() creates an nn.Module which you can add e.g. to an nn.Sequential model.\n",
        "#torch.relu on the other side is just the functional API call to the relu function,\n",
        "#so that you can add it e.g. in your forward method yourself.\n",
        "\n",
        "# option 1 (create nn modules)\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "# option 2 (use activation functions directly in forward pass)\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.relu(self.linear1(x))\n",
        "        out = torch.sigmoid(self.linear2(out))\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "xz58AEGKfIyB",
        "outputId": "15193474-095e-492e-cd42-fff6062172aa"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/2], Step [100/600], Loss: 0.2443\n",
            "Epoch [1/2], Step [200/600], Loss: 0.4088\n",
            "Epoch [1/2], Step [300/600], Loss: 0.1799\n",
            "Epoch [1/2], Step [400/600], Loss: 0.2345\n",
            "Epoch [1/2], Step [500/600], Loss: 0.2292\n",
            "Epoch [1/2], Step [600/600], Loss: 0.1024\n",
            "Epoch [2/2], Step [100/600], Loss: 0.2227\n",
            "Epoch [2/2], Step [200/600], Loss: 0.0999\n",
            "Epoch [2/2], Step [300/600], Loss: 0.1245\n",
            "Epoch [2/2], Step [400/600], Loss: 0.0834\n",
            "Epoch [2/2], Step [500/600], Loss: 0.1332\n",
            "Epoch [2/2], Step [600/600], Loss: 0.0820\n",
            "Accuracy of the network on the 10000 test images: 97.01 %\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "examples = iter(test_loader)\n",
        "example_data, example_targets = next(examples)\n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(example_data[i][0], cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [100, 1, 28, 28]\n",
        "        # resized: [100, 784]\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 10000 test images: {acc} %')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992
        },
        "id": "gwUBRCmkfl7v",
        "outputId": "7d726916-f12b-43a7-e4e3-15442a0b10b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:01<00:00, 101237528.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [2000/12500], Loss: 2.3229\n",
            "Epoch [1/5], Step [4000/12500], Loss: 2.3217\n",
            "Epoch [1/5], Step [6000/12500], Loss: 2.2472\n",
            "Epoch [1/5], Step [8000/12500], Loss: 2.2488\n",
            "Epoch [1/5], Step [10000/12500], Loss: 2.2529\n",
            "Epoch [1/5], Step [12000/12500], Loss: 1.6768\n",
            "Epoch [2/5], Step [2000/12500], Loss: 3.5774\n",
            "Epoch [2/5], Step [4000/12500], Loss: 3.1167\n",
            "Epoch [2/5], Step [6000/12500], Loss: 2.4207\n",
            "Epoch [2/5], Step [8000/12500], Loss: 1.9021\n",
            "Epoch [2/5], Step [10000/12500], Loss: 1.4541\n",
            "Epoch [2/5], Step [12000/12500], Loss: 1.6047\n",
            "Epoch [3/5], Step [2000/12500], Loss: 1.4228\n",
            "Epoch [3/5], Step [4000/12500], Loss: 1.8841\n",
            "Epoch [3/5], Step [6000/12500], Loss: 1.2562\n",
            "Epoch [3/5], Step [8000/12500], Loss: 1.4038\n",
            "Epoch [3/5], Step [10000/12500], Loss: 1.5286\n",
            "Epoch [3/5], Step [12000/12500], Loss: 0.6798\n",
            "Epoch [4/5], Step [2000/12500], Loss: 1.5911\n",
            "Epoch [4/5], Step [4000/12500], Loss: 1.7708\n",
            "Epoch [4/5], Step [6000/12500], Loss: 1.8876\n",
            "Epoch [4/5], Step [8000/12500], Loss: 2.2393\n",
            "Epoch [4/5], Step [10000/12500], Loss: 2.0148\n",
            "Epoch [4/5], Step [12000/12500], Loss: 0.5959\n",
            "Epoch [5/5], Step [2000/12500], Loss: 1.2555\n",
            "Epoch [5/5], Step [4000/12500], Loss: 1.3668\n",
            "Epoch [5/5], Step [6000/12500], Loss: 0.9898\n",
            "Epoch [5/5], Step [8000/12500], Loss: 1.1188\n",
            "Epoch [5/5], Step [10000/12500], Loss: 2.2468\n",
            "Epoch [5/5], Step [12000/12500], Loss: 1.9628\n",
            "Finished Training\n",
            "Accuracy of the network: 48.36 %\n",
            "Accuracy of plane: 36.9 %\n",
            "Accuracy of car: 55.4 %\n",
            "Accuracy of bird: 43.8 %\n",
            "Accuracy of cat: 34.1 %\n",
            "Accuracy of deer: 30.9 %\n",
            "Accuracy of dog: 45.8 %\n",
            "Accuracy of frog: 59.1 %\n",
            "Accuracy of horse: 54.0 %\n",
            "Accuracy of ship: 73.6 %\n",
            "Accuracy of truck: 50.0 %\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "num_epochs = 5\n",
        "batch_size = 4\n",
        "learning_rate = 0.001\n",
        "\n",
        "# dataset has PILImage images of range [0, 1].\n",
        "# We transform them to Tensors of normalized range [-1, 1]\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                         shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # -> n, 3, 32, 32\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # -> n, 16, 5, 5\n",
        "        x = x.view(-1, 16 * 5 * 5)            # -> n, 400\n",
        "        x = F.relu(self.fc1(x))               # -> n, 120\n",
        "        x = F.relu(self.fc2(x))               # -> n, 84\n",
        "        x = self.fc3(x)                       # -> n, 10\n",
        "        return x\n",
        "\n",
        "\n",
        "model = ConvNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n",
        "        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 2000 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print('Finished Training')\n",
        "PATH = './cnn.pth'\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    n_class_correct = [0 for i in range(10)]\n",
        "    n_class_samples = [0 for i in range(10)]\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            label = labels[i]\n",
        "            pred = predicted[i]\n",
        "            if (label == pred):\n",
        "                n_class_correct[label] += 1\n",
        "            n_class_samples[label] += 1\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "    for i in range(10):\n",
        "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "        print(f'Accuracy of {classes[i]}: {acc} %')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "taj-UhWHiEm4",
        "outputId": "0689fe68-4ee6-4751-96e6-2f8453209ca1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/1], Step [100/938], Loss: 0.2764\n",
            "Epoch [1/1], Step [200/938], Loss: 0.2420\n",
            "Epoch [1/1], Step [300/938], Loss: 0.2183\n",
            "Epoch [1/1], Step [400/938], Loss: 0.1561\n",
            "Epoch [1/1], Step [500/938], Loss: 0.3366\n",
            "Epoch [1/1], Step [600/938], Loss: 0.1190\n",
            "Epoch [1/1], Step [700/938], Loss: 0.0511\n",
            "Epoch [1/1], Step [800/938], Loss: 0.0956\n",
            "Epoch [1/1], Step [900/938], Loss: 0.3422\n",
            "Accuracy of the network on the 10000 test images: 96.44 %\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "############## TENSORBOARD ########################\n",
        "import sys\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "# default `log_dir` is \"runs\" - we'll be more specific here\n",
        "writer = SummaryWriter('runs/mnist1')\n",
        "###################################################\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 1\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "examples = iter(test_loader)\n",
        "example_data, example_targets = next(examples)\n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(example_data[i][0], cmap='gray')\n",
        "#plt.show()\n",
        "\n",
        "############## TENSORBOARD ########################\n",
        "img_grid = torchvision.utils.make_grid(example_data)\n",
        "writer.add_image('mnist_images', img_grid)\n",
        "#writer.close()\n",
        "#sys.exit()\n",
        "###################################################\n",
        "\n",
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "############## TENSORBOARD ########################\n",
        "writer.add_graph(model, example_data.reshape(-1, 28*28).to(device))\n",
        "#writer.close()\n",
        "#sys.exit()\n",
        "###################################################\n",
        "\n",
        "# Train the model\n",
        "running_loss = 0.0\n",
        "running_correct = 0\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [100, 1, 28, 28]\n",
        "        # resized: [100, 784]\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        running_correct += (predicted == labels).sum().item()\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "            ############## TENSORBOARD ########################\n",
        "            writer.add_scalar('training loss', running_loss / 100, epoch * n_total_steps + i)\n",
        "            running_accuracy = running_correct / 100 / predicted.size(0)\n",
        "            writer.add_scalar('accuracy', running_accuracy, epoch * n_total_steps + i)\n",
        "            running_correct = 0\n",
        "            running_loss = 0.0\n",
        "            ###################################################\n",
        "\n",
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "class_labels = []\n",
        "class_preds = []\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        values, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        class_probs_batch = [F.softmax(output, dim=0) for output in outputs]\n",
        "\n",
        "        class_preds.append(class_probs_batch)\n",
        "        class_labels.append(labels)\n",
        "\n",
        "    # 10000, 10, and 10000, 1\n",
        "    # stack concatenates tensors along a new dimension\n",
        "    # cat concatenates tensors in the given dimension\n",
        "    class_preds = torch.cat([torch.stack(batch) for batch in class_preds])\n",
        "    class_labels = torch.cat(class_labels)\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 10000 test images: {acc} %')\n",
        "\n",
        "    ############## TENSORBOARD ########################\n",
        "    classes = range(10)\n",
        "    for i in classes:\n",
        "        labels_i = class_labels == i\n",
        "        preds_i = class_preds[:, i]\n",
        "        writer.add_pr_curve(str(i), labels_i, preds_i, global_step=0)\n",
        "        writer.close()\n",
        "    ###################################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "LncRmUoxiREl",
        "outputId": "6aa7fa62-0551-4264-d687-1f589e3ab995"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.3335, -0.3796,  0.0356, -0.3357,  0.2682,  0.1143]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.2317], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.3335, -0.3796,  0.0356, -0.3357,  0.2682,  0.1143]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.2317], requires_grad=True)\n",
            "OrderedDict([('linear.weight', tensor([[ 0.3335, -0.3796,  0.0356, -0.3357,  0.2682,  0.1143]])), ('linear.bias', tensor([0.2317]))])\n",
            "OrderedDict([('linear.weight', tensor([[ 0.3335, -0.3796,  0.0356, -0.3357,  0.2682,  0.1143]])), ('linear.bias', tensor([0.2317]))])\n",
            "{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1]}]}\n",
            "{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1]}]}\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' SAVING ON GPU/CPU\\n\\n# 1) Save on GPU, Load on CPU\\ndevice = torch.device(\"cuda\")\\nmodel.to(device)\\ntorch.save(model.state_dict(), PATH)\\n\\ndevice = torch.device(\\'cpu\\')\\nmodel = Model(*args, **kwargs)\\nmodel.load_state_dict(torch.load(PATH, map_location=device))\\n\\n# 2) Save on GPU, Load on GPU\\ndevice = torch.device(\"cuda\")\\nmodel.to(device)\\ntorch.save(model.state_dict(), PATH)\\n\\nmodel = Model(*args, **kwargs)\\nmodel.load_state_dict(torch.load(PATH))\\nmodel.to(device)\\n\\n# Note: Be sure to use the .to(torch.device(\\'cuda\\')) function\\n# on all model inputs, too!\\n\\n# 3) Save on CPU, Load on GPU\\ntorch.save(model.state_dict(), PATH)\\n\\ndevice = torch.device(\"cuda\")\\nmodel = Model(*args, **kwargs)\\nmodel.load_state_dict(torch.load(PATH, map_location=\"cuda:0\"))  # Choose whatever GPU device number you want\\nmodel.to(device)\\n\\n# This loads the model to a given GPU device.\\n# Next, be sure to call model.to(torch.device(\\'cuda\\')) to convert the model’s parameter tensors to CUDA tensors\\n'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "''' 3 DIFFERENT METHODS TO REMEMBER:\n",
        " - torch.save(arg, PATH) # can be model, tensor, or dictionary\n",
        " - torch.load(PATH)\n",
        " - torch.load_state_dict(arg)\n",
        "'''\n",
        "\n",
        "''' 2 DIFFERENT WAYS OF SAVING\n",
        "# 1) lazy way: save whole model\n",
        "torch.save(model, PATH)\n",
        "\n",
        "# model class must be defined somewhere\n",
        "model = torch.load(PATH)\n",
        "model.eval()\n",
        "\n",
        "# 2) recommended way: save only the state_dict\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "# model must be created again with parameters\n",
        "model = Model(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.eval()\n",
        "'''\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear = nn.Linear(n_input_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred\n",
        "\n",
        "model = Model(n_input_features=6)\n",
        "# train your model...\n",
        "\n",
        "####################save all ######################################\n",
        "for param in model.parameters():\n",
        "    print(param)\n",
        "\n",
        "# save and load entire model\n",
        "\n",
        "FILE = \"model.pth\"\n",
        "torch.save(model, FILE)\n",
        "\n",
        "loaded_model = torch.load(FILE)\n",
        "loaded_model.eval()\n",
        "\n",
        "for param in loaded_model.parameters():\n",
        "    print(param)\n",
        "\n",
        "\n",
        "############save only state dict #########################\n",
        "\n",
        "# save only state dict\n",
        "FILE = \"model.pth\"\n",
        "torch.save(model.state_dict(), FILE)\n",
        "\n",
        "print(model.state_dict())\n",
        "loaded_model = Model(n_input_features=6)\n",
        "loaded_model.load_state_dict(torch.load(FILE)) # it takes the loaded dictionary, not the path file itself\n",
        "loaded_model.eval()\n",
        "\n",
        "print(loaded_model.state_dict())\n",
        "\n",
        "\n",
        "###########load checkpoint#####################\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "checkpoint = {\n",
        "\"epoch\": 50,\n",
        "\"model_state\": model.state_dict(),\n",
        "\"optim_state\": optimizer.state_dict()\n",
        "}\n",
        "print(optimizer.state_dict())\n",
        "FILE = \"checkpoint.pth\"\n",
        "torch.save(checkpoint, FILE)\n",
        "\n",
        "model = Model(n_input_features=6)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0)\n",
        "\n",
        "checkpoint = torch.load(FILE)\n",
        "model.load_state_dict(checkpoint['model_state'])\n",
        "optimizer.load_state_dict(checkpoint['optim_state'])\n",
        "epoch = checkpoint['epoch']\n",
        "\n",
        "model.eval()\n",
        "# - or -\n",
        "# model.train()\n",
        "\n",
        "print(optimizer.state_dict())\n",
        "\n",
        "# Remember that you must call model.eval() to set dropout and batch normalization layers\n",
        "# to evaluation mode before running inference. Failing to do this will yield\n",
        "# inconsistent inference results. If you wish to resuming training,\n",
        "# call model.train() to ensure these layers are in training mode.\n",
        "\n",
        "\"\"\" SAVING ON GPU/CPU\n",
        "\n",
        "# 1) Save on GPU, Load on CPU\n",
        "device = torch.device(\"cuda\")\n",
        "model.to(device)\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "device = torch.device('cpu')\n",
        "model = Model(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH, map_location=device))\n",
        "\n",
        "# 2) Save on GPU, Load on GPU\n",
        "device = torch.device(\"cuda\")\n",
        "model.to(device)\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "model = Model(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.to(device)\n",
        "\n",
        "# Note: Be sure to use the .to(torch.device('cuda')) function\n",
        "# on all model inputs, too!\n",
        "\n",
        "# 3) Save on CPU, Load on GPU\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "model = Model(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH, map_location=\"cuda:0\"))  # Choose whatever GPU device number you want\n",
        "model.to(device)\n",
        "\n",
        "# This loads the model to a given GPU device.\n",
        "# Next, be sure to call model.to(torch.device('cuda')) to convert the model’s parameter tensors to CUDA tensors\n",
        "\"\"\"\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
